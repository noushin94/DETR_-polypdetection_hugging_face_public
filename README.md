
Polyp Detection

Automatic image detection in colonoscopic images has been a challenging problem for years. Due to the varying sizes and diverse appearances of polyps, along with differing detection techniques and opinions from clinicians, computer-aided systems have been utilized to facilitate polyp detection and ensure patients benefit from accurate and precise recognition. Numerous articles have explored different neural networks for object detection, ranging from RCNNs to the latest iterations of the well-known You Only Look Once (YOLO) model, aiming to achieve the highest accuracy in this demanding area.

Although the results of these models have generally been outstanding, working with human health is more sensitive than other applications in automated systems. Fast diagnosis and high accuracy are two crucial aspects that must be strictly considered to avoid any failures in this sensitive project. To address the need for both high speed and faultlessness, we plan to implement a transformer learning technique for polyp detection, specifically DEtection TRansformers (DETR). This approach will reduce the need for extensive hyperparameter tuning, such as anchor boxes utilized in previous models, and, based on an encoder-decoder architecture, will allow the model to capture more meaningful information from the dataset, resulting in a more comprehensive understanding of the data.
Polyp Detection with DETR

Our objective is to develop a model that not only performs object detection in a single step but also incorporates a mechanism for self-attention. Integrating self-attention into the model is crucial because it allows the network to focus on different parts of the input image selectively, enhancing its ability to discern and differentiate objects more accurately. This dual functionality aims to streamline the object detection process, reducing computational complexity and improving efficiency. By embedding self-attention mechanisms, the model can dynamically prioritize relevant features, leading to more robust and precise detection outcomes. This approach leverages the strengths of self-attention to refine the detection process, making it more adaptive and contextually aware, thereby advancing the state-of-the-art in object detection methodologies (Niu, Zhong, and Yu, 2021).

Self-attention mechanisms, predominantly utilized in Natural Language Processing (NLP) models, are essential due to their ability to provide a comprehensive understanding of words within sentences by capturing the contextual information conveyed by the entire sentence. This capability allows models, such as Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2018), to perform remarkably well in NLP tasks by effectively interpreting the meaning of words in a given context. BERT achieves this by employing a transformer architecture, which uses self-attention to dynamically weigh the importance of each word in relation to others in the sentence, thus enabling the model to grasp nuanced meanings and relationships.

However, the application of self-attention extends beyond NLP and holds significant potential for enhancing computer vision tasks. (Carion et al., 2020) demonstrated this with the Detection Transformer (DETR) model, which combines a convolutional neural network (CNN) for initial feature extraction with a transformer-based encoder-decoder architecture that leverages self-attention. In this setup, the self-attention mechanism within the encoder assigns meaning to each image feature based on its spatial relationships with other features, allowing the model to capture intricate relationships between different parts of the image. This method enhances the interpretative accuracy of the model by enabling it to understand the image more holistically rather than relying solely on superficial feature information.

Integrating self-attention in computer vision models addresses the limitations of traditional CNNs, which often struggle with capturing long-range dependencies and contextual relationships within images. By employing self-attention, the DETR model effectively bridges this gap, leading to more robust and precise object detection and image interpretation. This innovative application underscores the versatility of self-attention mechanisms and their potential to advance various domains of artificial intelligence by enabling models to process and understand complex data more effectively. The architecture of DETR is straightforward and consists of three main components, as illustrated in Figure 1: a CNN backbone, an encoder-decoder transformer, and a simple feed-forward network (FFN). The CNN backbone is responsible for extracting initial features from the input images. These features are then passed to the encoder-decoder transformer, which uses self-attention mechanisms to capture spatial relationships and contextual information within the image. Finally, the output of the transformer is fed into a simple feed-forward network that predicts the object classes and their bounding boxes. This cohesive structure allows DETR to perform end-to-end object detection with high accuracy and efficiency (Mohammad, Sharma, and Das, 2022).

<img width="331" alt="image" src="https://github.com/user-attachments/assets/85caaeab-a21b-4138-834e-7e972f67ec1d">


FIGURE 1 (Mohammad, Sharma, and Das, 2022)

To address the need for one-step object detection, the Detection Transformer (DETR) model utilizes a Hungarian-based algorithm for object detection. The Hungarian algorithm, also known as the Kuhn-Munkres algorithm, is employed to solve the assignment problem, ensuring an optimal matching between predicted and ground truth objects. In the context of DETR, this approach allows the model to efficiently match predicted bounding boxes with their corresponding ground truth boxes, minimizing the overall cost in a single step. By incorporating this algorithm, DETR eliminates the need for multiple stages of object detection and post-processing, streamlining the detection process. This method ensures that each detected object is uniquely assigned to a prediction, improving the accuracy and reliability of the detection results. The integration of the Hungarian algorithm into the DETR framework thus supports the goal of achieving efficient and precise one-step object detection (Carion et al., 2020).
Repository Overview

This repository hosts a cutting-edge polyp detection system using the DETR (Detection Transformer) model, developed to identify polyps from medical images efficiently. This project leverages datasets sourced from Roboflow and models from Hugging Face, ensuring a robust and scalable solution for medical imaging tasks.
Project Overview

Our polyp detection system employs the DETR model, a transformer-based architecture known for its effectiveness in object detection tasks. By utilizing datasets from Roboflow and pretrained models from Hugging Face, this system is designed to integrate seamlessly into medical diagnostic workflows, offering high accuracy and reliability.
Features

    High accuracy polyp detection using the DETR model.
    Integration with Hugging Face for advanced model management.
    Use of Roboflow datasets to enhance training and validation processes.
